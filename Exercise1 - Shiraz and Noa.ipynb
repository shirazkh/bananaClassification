{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfd420ed",
   "metadata": {
    "id": "cfd420ed"
   },
   "source": [
    "### Problem Definition\n",
    "\n",
    "In this project, we build an image classifier that predicts the ripeness level of bananas from a single RGB image.\n",
    "\n",
    "The model predicts one of three classes:\n",
    "- **Unripe** - mostly green peel\n",
    "- **Ripe** - mostly yellow peel, suitable for eating\n",
    "- **Overripe** - dark spotted/brown peel, very soft and close to or beyond ideal eating point\n",
    "\n",
    "#### Real-world motivation\n",
    "\n",
    "Banana ripeness is a practical problem in agriculture, retail and at home. Being able to automatically estimate ripeness from images can help with:\n",
    "\n",
    "- **Quality control** in supermarkets (sorting bananas into “ready to sell today” vs “too green” vs “too late”).\n",
    "- **Food waste reduction**, by detecting overripe fruit earlier and discounting or redirecting it to other uses (e.g. baking, smoothies).\n",
    "- **Assisting consumers** in choosing bananas according to their preference (some people like greener bananas, some prefer very ripe).\n",
    "\n",
    "In this project we do not try to solve the full industrial problem, but we build a small, reproducible prototype that shows how a deep learning model can classify banana ripeness from images using transfer learning.\n",
    "\n",
    "#### Expected Challenges\n",
    "\n",
    "- **Ambiguous boundaries between classes**  \n",
    "  There is no sharp line between “ripe” and “overripe” – some bananas are in-between, which makes labels somewhat subjective.\n",
    "\n",
    "- **Lighting and background conditions**  \n",
    "  Images may be taken under different illumination (indoor, outdoor, shadows, warm/cold light) and on different backgrounds, which changes the perceived color.\n",
    "\n",
    "- **Multiple bananas in one image**  \n",
    "  Some images may contain more than one banana with slightly different ripeness levels. The dataset label is still a single class for the whole image.\n",
    "\n",
    "- **Color similarity between classes**  \n",
    "  Slightly yellow-green bananas can look similar to ripe ones, and dark-spotted ripe bananas can look similar to overripe ones, which may cause confusion for the model.\n",
    "\n",
    "- **Dataset shift to real world**  \n",
    "  The training images are relatively clean and focused on bananas. In real supermarket shelves, bananas might be partially occluded, far from the camera, or mixed with other fruits. The model may not generalize perfectly to such settings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a3e53f",
   "metadata": {
    "id": "42a3e53f"
   },
   "source": [
    "### Dataset source\n",
    "\n",
    "We used the public **Banana Classification** dataset from Kaggle, which contains 4 categories: *Unripe*, *Ripe*, and *Rotten*.\n",
    "\n",
    "Dataset citation:\n",
    "Jorgusheska, I. (2022). *Banana Ripeness Level Recognition Dataset*  \n",
    "GitHub repository: https://github.com/IvaJorgusheska/Banana_Ripeness_Level_Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12105809",
   "metadata": {
    "id": "12105809"
   },
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_ROOT = Path(\"data\")\n",
    "BANANA_PATH = DATA_ROOT / \"bananas\"\n",
    "\n",
    "DATA_ROOT, BANANA_PATH\n",
    "\n",
    "if not BANANA_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Didn't find {BANANA_PATH}. \"\n",
    "        \"Make sure you have data/bananas/unripe, ripe, rotten inside the repo.\"\n",
    "    )\n",
    "\n",
    "for cls_dir in sorted(BANANA_PATH.iterdir()):\n",
    "    if cls_dir.is_dir():\n",
    "        n = len(list(cls_dir.glob(\"*\")))\n",
    "        print(f\"{cls_dir.name}: {n} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6dc95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = BANANA_PATH\n",
    "\n",
    "dls = ImageDataLoaders.from_folder(\n",
    "    path,\n",
    "    valid_pct=0.2,   # 80% train, 20% validation\n",
    "    seed=42,\n",
    "    item_tfms=Resize(224)\n",
    ")\n",
    "\n",
    "dls.show_batch(max_n=9, figsize=(6,6))\n",
    "print(\"Classes:\", dls.vocab)\n",
    "\n",
    "learn = vision_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.fine_tune(5)\n",
    "\n",
    "acc = learn.validate()[1]\n",
    "print(f\"Validation accuracy: {acc:.4f}\")\n",
    "\n",
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix(figsize=(4,4))\n",
    "\n",
    "from random import choice\n",
    "\n",
    "valid_items = dls.valid.items\n",
    "\n",
    "for _ in range(5):\n",
    "    img_path = choice(valid_items)\n",
    "    img = PILImage.create(img_path)\n",
    "    pred, pred_idx, probs = learn.predict(img)\n",
    "\n",
    "    display(img.to_thumb(256, 256))\n",
    "    print(f\"True label    : {img_path.parent.name}\")\n",
    "    print(f\"Predicted     : {pred}\")\n",
    "    print(f\"Probabilities : {probs}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# learn.export(\"banana_ripeness_resnet18.pkl\")\n",
    "# print(\"Model exported to banana_ripeness_resnet18.pkl\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
